# -*- coding: utf-8 -*-
"""W4_IP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bfK0v_rHZ1Cevze6IMF-QXrmxjZclp-p

In this week's independent project, you will be working as a data scientist working for an electric car-sharing service company. You have been tasked to process stations data to understand electric car usage over time by solving for the following research question;

Research Question

Identify the most popular hour of the day for picking up a shared electric car (Bluecar) in the city of Paris over the month of April 2018.

# DATA PREPARATION
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing Libraries we could use in the analysis

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

# Loading the dataset into the environment
Autolib = pd.read_csv('Autolib_dataset (2).csv')
Autolib

Autolib.describe()

Autolib.info()

"""# DATA CLEANING

## BLUE CAR ONLY
"""

# Checking if the Cars and Blue_Counter columns hold the same values.

Autolib_Check = Autolib.Cars == Autolib['Bluecar counter']
Autolib_Check.describe()
# As expected, they do, so we can drop the Cars column.

# Checking the relationship between ID, Public name, Postal code and Address
print(Autolib.ID.describe())
print(Autolib['Public name'].describe())

print(Autolib['Postal code'].value_counts())
Autolib.Address.describe()
# ID corresponds to Public name. They both correspond to Address but there seems to be 1 outlier.
# Postal code seems to be different from the above.

# We'll drop ID and Public Name regardless, as we want to know the Addresses and Postal Codes.

# Dropping unrequired columns

Bluecar = Autolib.drop(['Cars','Utilib counter','Utilib 1.4 counter','Displayed comment','ID','Kind','Geo point','Public name','Subscription status'], axis=1)
Bluecar.head()

Bluecar.columns = Bluecar.columns.str.replace(' ', '_')

# We need to convert the days and time to datetime for easier Analysis
# First let's convert them to objects i.e. strings
print(Bluecar.info())

Bluecar.year = Bluecar.year.astype(str)
Bluecar.month = Bluecar.month.astype(str)
Bluecar.day = Bluecar.day.astype(str)

Bluecar.hour = Bluecar.hour.astype(str)
Bluecar.minute = Bluecar.minute.astype(str)

Bluecar.info()

Bluecar.head()

# Next we concatenate them

Blue = Bluecar['year'] + Bluecar['month'] + Bluecar['day']
print(Blue.head())
Test = pd.to_datetime(Blue, format='%Y%m%d', errors='ignore')
print(Test.head())

Time = Bluecar.hour + Bluecar.minute
print(Time.head())

Time_Test = pd.to_datetime(Time, format= '%H%M').dt.time # option 1 gives dtype as object, which will be hard to work with in calculations
print(Time_Test.head())

Time_Test2 = pd.to_datetime(Time, format= '%H%M')- pd.to_datetime(Time, format='%H%M').dt.normalize()
Time_Test2 # option 2 is better due to the datatype timedelta.

Bluecar.head()

# After Analysis, it's better to convert only the Year Month and Days to Date_Time and leave the hours as is.
# Furthermore, since the analysis is on hours, the minute column can be dropped.

Bluecar.hour = Bluecar.hour.astype(int)
Bluecar.minute = Bluecar.minute.astype(int)
Bluecar.info()

Bluecar['Date'] = Test
Bluecar.head()

# We can now drop year, month and day columns
# Additionally, since the analysis is on hours, the minute column can be dropped.

Bluecar.drop(['year', 'month', 'day', 'minute'], axis=1, inplace= True)
Bluecar.head()

"""### Outliers"""

# From the data below, the max values of Bluecar_counter, Charge_slots and slots seems to be far 
# from the rest of the data. Futhermore they're far from the 75th percentile. further investigation 
# should be done to see if they affect the data.
# Values for Postal_code and hours do not count in this, as they are uniquely standardized units.

Bluecar.describe()

# From the data below, the max value seems to be far from the rest of the data It's far 
# from the 75th percentile, further investigation should be done to see if it affects the data 
Bluecar.hour.value_counts()
# This gives us a hint that 21:00 hrs could be the most popular hour. this will be investigated
# during data analysis.

# First we'll store a copy of the original in order to manipulate the data and still have a copy of
# the original to compare results with

Bluecar_with_possible_outliers = Bluecar.copy()
Bluecar_with_possible_outliers.head()

