# -*- coding: utf-8 -*-
"""W4_IP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bfK0v_rHZ1Cevze6IMF-QXrmxjZclp-p

In this week's independent project, you will be working as a data scientist working for an electric car-sharing service company. You have been tasked to process stations data to understand electric car usage over time by solving for the following research question;

Research Question

Identify the most popular hour of the day for picking up a shared electric car (Bluecar) in the city of Paris over the month of April 2018.

# DATA PREPARATION
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing Libraries we could use in the analysis

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

# Loading the dataset into the environment
Autolib = pd.read_csv('Autolib_dataset (2).csv')
Autolib

Autolib.describe()

Autolib.info()

"""# DATA CLEANING

## BLUE CAR ONLY
"""

# Checking if the Cars and Blue_Counter columns hold the same values.

Autolib_Check = Autolib.Cars == Autolib['Bluecar counter']
Autolib_Check.describe()
# As expected, they do, so we can drop the Cars column.

# Checking the relationship between ID, Public name, Postal code and Address
print(Autolib.ID.describe())
print(Autolib['Public name'].describe())

print(Autolib['Postal code'].value_counts())
Autolib.Address.describe()
# ID corresponds to Public name. They both correspond to Address but there seems to be 1 outlier.
# Postal code seems to be different from the above.

# We'll drop ID and Public Name regardless, as we want to know the Addresses and Postal Codes.

# Dropping unrequired columns

Bluecar = Autolib.drop(['Cars','Utilib counter','Utilib 1.4 counter','Displayed comment','ID','Kind','Geo point','Public name','Subscription status'], axis=1)
Bluecar.head()

Bluecar.columns = Bluecar.columns.str.replace(' ', '_')

# We need to convert the days and time to datetime for easier Analysis
# First let's convert them to objects i.e. strings
print(Bluecar.info())

Bluecar.year = Bluecar.year.astype(str)
Bluecar.month = Bluecar.month.astype(str)
Bluecar.day = Bluecar.day.astype(str)

Bluecar.hour = Bluecar.hour.astype(str)
Bluecar.minute = Bluecar.minute.astype(str)

Bluecar.info()

Bluecar.head()

# Next we concatenate them

Blue = Bluecar['year'] + Bluecar['month'] + Bluecar['day']
print(Blue.head())
Test = pd.to_datetime(Blue, format='%Y%m%d', errors='ignore')
print(Test.head())

Time = Bluecar.hour + Bluecar.minute
print(Time.head())

Time_Test = pd.to_datetime(Time, format= '%H%M').dt.time # option 1 gives dtype as object, which will be hard to work with in calculations
print(Time_Test.head())

Time_Test2 = pd.to_datetime(Time, format= '%H%M')- pd.to_datetime(Time, format='%H%M').dt.normalize()
Time_Test2 # option 2 is better due to the datatype timedelta.

Bluecar.head()

# After Analysis, it's better to convert only the Year Month and Days to Date_Time and leave the hours as is.
# Furthermore, since the analysis is on hours, the minute column can be dropped.

Bluecar.hour = Bluecar.hour.astype(int)
Bluecar.minute = Bluecar.minute.astype(int)
Bluecar.info()

Bluecar['Date'] = Test
Bluecar.head()

# We can now drop year, month and day columns
# Additionally, since the analysis is on hours, the minute column can be dropped.

Bluecar.drop(['year', 'month', 'day', 'minute'], axis=1, inplace= True)
Bluecar.head()

"""### Outliers"""

# From the data below, the max values of Bluecar_counter, Charge_slots and slots seems to be far
# from the rest of the data. Futhermore they're far from the 75th percentile. further investigation
# should be done to see if they affect the data.
# Values for Postal_code and hours do not count in this, as they are uniquely standardized units.

Bluecar.describe()

# From the data below, the max value seems to be far from the rest of the data It's far
# from the 75th percentile, further investigation should be done to see if it affects the data
Bluecar.hour.value_counts()

# First we'll store a copy of the original in order to manipulate the data and still have a copy of
# the original to compare results with, incase any transformations occur.

Blue = Bluecar.copy(deep=True)
Blue.head()

# There seems to be no outliers
Bluecar.boxplot(column='Bluecar_counter', by='hour')
Bluecar.boxplot(column='Slots', by='hour')

"""# DATA ANALYSIS

## BLUECAR ONLY
"""

# We will only be working with Paris.

Blue = Blue[Blue.City == 'Paris']
Blue.head()

# Sorting the table in order of days ascending.
Blue = Blue.sort_values(by=['Address', 'Date', 'hour'])
Blue

Engaged_Addresses = Blue.copy(deep=True)
Engaged_Addresses = Engaged_Addresses[Engaged_Addresses['Address'] == Engaged_Addresses['Address'].shift(1)] # If the address below is equal to the current address

# if address below is similar to current address, subtract to get no.of cars picked up.
Engaged_Addresses.loc[Engaged_Addresses.Address == Engaged_Addresses.Address.shift(-1), 'taken'] = Engaged_Addresses['Bluecar_counter'] - Engaged_Addresses['Bluecar_counter'].shift(-1)
Engaged_Addresses.head()
# From this we notice that addresses that appear only once means no picking up of cars or returning was done.
# We can ignore these adresses as we have done above.
# 'taken' Null values and negatives should be replaced with 0 since they mean no cars were picked.

Engaged_Addresses.taken.fillna(0, inplace= True)
Engaged_Addresses.taken.value_counts()
# We can replace the negative values listed below.

Engaged_Addresses.taken = Engaged_Addresses.taken.replace([-1,-2,-3,-4,-5,-6,-7], 0)
Engaged_Addresses.taken.value_counts()
# Now we have the cars taken/ picked up.

"""#### Answering Questions posed on the CRISP-DM Document's Analysis Section
Per Day Analysis
"""

# 1. The most popular day with the most rides.
Engaged_Addresses.groupby('Date')['taken'].sum().sort_values(ascending=False)

# 2. The least popular day with the least rides.
Engaged_Addresses.groupby('Date')['taken'].sum().sort_values(ascending=True)

"""#### Hours Analysis"""

# 1. The most popular hours (working or home hours).
# From the calendar weekends are 1st, 7th and 8th

Engaged_hours = Engaged_Addresses.copy(deep= True)
Weekday_hours = Engaged_hours[((Engaged_hours.hour >= 8) & (Engaged_hours.hour <= 18)) & ((Engaged_hours.Date != '2018-04-01') & (Engaged_hours.Date != '2018-04-07') & (Engaged_hours.Date != '2018-04-08'))]
Weekday_hours.groupby('hour')['taken'].sum().sort_values(ascending=False)

Weekday_hours_night = Engaged_hours[((Engaged_hours.hour < 8) | (Engaged_hours.hour > 18)) & ((Engaged_hours.Date != '2018-04-01') & (Engaged_hours.Date != '2018-04-07') & (Engaged_hours.Date != '2018-04-08'))]
Weekday_hours_night.groupby('hour')['taken'].sum().sort_values(ascending=False)

# 2. The least popular hours (working or home hours)
Weekday_hours.groupby('hour')['taken'].sum().sort_values(ascending=True)

Weekday_hours_night.groupby('hour')['taken'].sum().sort_values(ascending=True)

print('Day rides :', Weekday_hours.taken.sum())
print('Night rides :', Weekday_hours_night.taken.sum())

# The above was for weekdays
# Below, we'll consider weekends.
#Most popular hours day time.
Weekend_hours = Engaged_hours[((Engaged_hours.hour >= 8) & (Engaged_hours.hour <= 18)) & ((Engaged_hours.Date == '2018-04-01') | (Engaged_hours.Date == '2018-04-07') | (Engaged_hours.Date == '2018-04-08'))]
Weekend_hours.groupby('hour')['taken'].sum().sort_values(ascending= False)

#Most popular hours night time
Weekend_hours_night = Engaged_hours[((Engaged_hours.hour < 8) | (Engaged_hours.hour > 18)) & ((Engaged_hours.Date == '2018-04-01') | (Engaged_hours.Date == '2018-04-07') | (Engaged_hours.Date == '2018-04-08'))]
Weekend_hours_night.groupby('hour')['taken'].sum().sort_values(ascending= False)

#Least popular day hours
Weekend_hours.groupby('hour')['taken'].sum().sort_values(ascending= True)

#Least popular night hours
Weekend_hours_night.groupby('hour')['taken'].sum().sort_values(ascending= True)

print('Day rides: ', Weekend_hours.taken.sum())
print('Night rides: ', Weekend_hours_night.taken.sum())

a = Weekday_hours.taken.sum() + Weekend_hours.taken.sum()
b = Weekday_hours_night.taken.sum() + Weekend_hours_night.taken.sum()

print("Week's total day rides = ", a)
print("Week's total night rides = ", b)

# Least popular hours inclusive of weekdays and weekends
Engaged_hours.groupby('hour')['taken'].sum().sort_values(ascending= True)

# Most popular hours inclusive of weekdays and weekends
Engaged_hours.groupby('hour')['taken'].sum().sort_values(ascending= False)

Engaged_hours.Address.value_counts()

Engaged_hours

Test = Engaged_hours[Engaged_hours.Address == '8 Avenue de la Porte de Montrouge']
Test

# 3. Returning hours

Engaged_hours.loc[Engaged_hours.Address == Engaged_hours.Address.shift(-1), 'returned'] = Engaged_hours['Bluecar_counter'] - Engaged_hours['Bluecar_counter'].shift(-1)
Engaged_hours[Engaged_hours.Address == '8 Avenue de la Porte de Montrouge'] # Preview after the subtraction operation above.

#From this we need only the negative numbers as they represent the returned cars.

Engaged_hours.returned.fillna(0, inplace= True)
Engaged_hours.returned.value_counts()

Engaged_hours.returned = Engaged_hours.returned.replace([1,2,3,4,5,6,7], 0)
Engaged_hours.returned.value_counts()

# Convert the negative values to positive values
Engaged_hours.returned = Engaged_hours.returned.abs()
Engaged_hours

# a.)  The most popular hours (working or home hours) for returning cars
# day hours weekday
Return_Weekday = Engaged_hours[((Engaged_hours.hour >= 8) & (Engaged_hours.hour <= 18)) & ((Engaged_hours.Date != '2018-04-01') & (Engaged_hours.Date != '2018-04-07') & (Engaged_hours.Date != '2018-04-08'))]
Return_Weekday.groupby('hour')['returned'].sum().sort_values(ascending=False)

# night hours weekday
Return_Weekday_night = Engaged_hours[((Engaged_hours.hour < 8) | (Engaged_hours.hour > 18)) & ((Engaged_hours.Date != '2018-04-01') & (Engaged_hours.Date != '2018-04-07') & (Engaged_hours.Date != '2018-04-08'))]
Return_Weekday_night.groupby('hour')['returned'].sum().sort_values(ascending=False)

# b.) The least popular hours (working or home hours) for returns
# day hours weekday
Return_Weekday.groupby('hour')['returned'].sum().sort_values(ascending=True)

# night hours weekday
Return_Weekday_night.groupby('hour')['returned'].sum().sort_values(ascending=True)

print('Day rides :', Return_Weekday.returned.sum())
print('Night rides :', Return_Weekday_night.returned.sum())

# Below, we'll consider weekends.
#Most popular hours day time.
Returned_Weekend = Engaged_hours[((Engaged_hours.hour >= 8) & (Engaged_hours.hour <= 18)) & ((Engaged_hours.Date == '2018-04-01') | (Engaged_hours.Date == '2018-04-07') | (Engaged_hours.Date == '2018-04-08'))]
Returned_Weekend.groupby('hour')['returned'].sum().sort_values(ascending= False)

#Most popular hours night time
Returned_Weekend_night = Engaged_hours[((Engaged_hours.hour < 8) | (Engaged_hours.hour > 18)) & ((Engaged_hours.Date == '2018-04-01') | (Engaged_hours.Date == '2018-04-07') | (Engaged_hours.Date == '2018-04-08'))]
Returned_Weekend_night.groupby('hour')['returned'].sum().sort_values(ascending= False)

# Least popular day time
Returned_Weekend.groupby('hour')['returned'].sum().sort_values(ascending= True)

# Least popular night time
Returned_Weekend_night.groupby('hour')['returned'].sum().sort_values(ascending= True)

print('Day returns: ', Returned_Weekend.returned.sum())
print('Night returns: ', Returned_Weekend_night.returned.sum())

c = Return_Weekday.returned.sum() + Returned_Weekend.returned.sum()
d = Return_Weekday_night.returned.sum() + Returned_Weekend_night.returned.sum()

print("Week's total day returns = ", c)
print("Week's total night returns = ", d)

# Least popular hours for returns weekdays and weekends inclusive
Engaged_hours.groupby('hour')['returned'].sum().sort_values(ascending= True)

# Most popular hours for returns weekdays and weekends inclusive
Engaged_hours.groupby('hour')['returned'].sum().sort_values(ascending= False)

"""#### Stations Analysis"""

Engaged_hours

# The most popular station
Stations = Engaged_hours.copy(deep= True)
Stations

# for picking up cars
Stations.groupby('Address')['taken'].sum().sort_values(ascending=False)

# for returning cars
Stations.groupby('Address')['returned'].sum().sort_values(ascending=False)

# for all activity (returned + picked up)
Stations['activity'] = Stations['taken'] + Stations['returned']
Stations.groupby('Address')['activity'].sum().sort_values(ascending= False)

# Least popular station
# for picking cars
Stations.groupby('Address')['taken'].sum().sort_values(ascending=True)

# for returning cars
Stations.groupby('Address')['returned'].sum().sort_values(ascending=True)

# for all activity (returned + picked up)
Stations.groupby('Address')['activity'].sum().sort_values(ascending= True)

Stations

# 2. The most popular stations determined by the most popular hours to visit them.
#Weekday working hours pickups

Stations.hour = Stations.hour.astype(int)
Weekday_hours.groupby(['Address','hour'])['taken'].sum().sort_values(ascending=False)

# Weekday working hours returns
Return_Weekday.groupby(['Address','hour'])['returned'].sum().sort_values(ascending=False)

# Weekend day hours

Weekend_hours.groupby(['Address','hour'])['taken'].sum().sort_values(ascending=False)

# For returns

Returned_Weekend.groupby(['Address','hour'])['returned'].sum().sort_values(ascending=False)

# Weekday home hours
Weekday_hours_night.groupby(['Address','hour'])['taken'].sum().sort_values(ascending=False)

# For returns
Return_Weekday_night.groupby(['Address','hour'])['returned'].sum().sort_values(ascending=False)

# Weekend night hours
Weekend_hours_night.groupby(['Address','hour'])['taken'].sum().sort_values(ascending=False)

# Weekend night hours returns
Returned_Weekend_night.groupby(['Address','hour'])['taken'].sum().sort_values(ascending=False)

"""#### Postcode Analysis"""

# Top Address can be seen as 8 Avenue de la Porte de Montrouge
Stations.groupby('Address')['activity'].sum().sort_values(ascending= False)

# Top Post Code can be seen as 75015
Stations.groupby('Postal_code')['activity'].sum().sort_values(ascending= False)

# Check 1 to see if 8 Avenue de la Porte de Montrouge is in 75015
Post = Stations[Stations.Postal_code == 75015]
Post[Post.Address == '8 Avenue de la Porte de Montrouge']

#Check 2 for 75015 in 8 Avenue de la Porte de Montrouge
Stations[Stations.Address == '8 Avenue de la Porte de Montrouge']
#As can be seen the Postal_Code for the top address is 75014 and not 75015

"""# RECOMMENDATION

Since no data was provided about the pick up and return times, calculations had to be done to determine them by subtracting consecutive available cars within the same address, arranged by time of day and eventually days. This was a lengthy process and to avoid mistakes in future, it is recommended that the data is collected including these two important variables. From the analysis, the most popular days seem to be the weekdays, especially Wednesday to Friday, while the least popular are the weekends. This could be caused by heightened economic activity during the weekdays as most work is carried out then. The most popular time for both activities (pick ups and returns) is home time rather than working time. This could be a result of people leaving their workplace, hence able to engage with the service mostly after or before work. Additionally, in between the day, at around lunchtime there seems to be large activity as people could be free to engage with the service. As was observed, the top stations in general did not have a single hour in which they had dominant activity when compared to the other stations. This is to be expected as the busier the station, the more traffic will be spread out within different hours. Finally, the most popular address was not in the most popular post code. This is because there were more busy stations in the 75015 postcode, even  though they were not the top station. This could suggest that postcode 75015 is in a busier environment, where there’s more customer engagement with the product when compared to other postcodes.
"""
